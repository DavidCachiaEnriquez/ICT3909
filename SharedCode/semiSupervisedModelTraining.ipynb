{"cells":[{"cell_type":"markdown","metadata":{"id":"HDKev4lhb-9T"},"source":["## Instal Toolkit, Import Libraries, Access Google Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ivt8_-T4LCSD"},"outputs":[],"source":["# Imports\n","\n","# General Libraries\n","import numpy as np\n","import pandas as pd\n","import time\n","import random\n","\n","# For Training\n","from sklearn.model_selection import GroupKFold\n","\n","# Measurements\n","from LAMDA_SSL.Evaluation.Classifier.Accuracy import Accuracy\n","from LAMDA_SSL.Evaluation.Classifier.Precision import Precision\n","from LAMDA_SSL.Evaluation.Classifier.Confusion_Matrix import Confusion_Matrix\n","\n","# Supervised Models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","# Semi-Supervised Models\n","from LAMDA_SSL.Algorithm.Classification.Co_Training import Co_Training\n","from LAMDA_SSL.Algorithm.Classification.Tri_Training import Tri_Training\n","from LAMDA_SSL.Algorithm.Classification.SSGMM import SSGMM\n","from LAMDA_SSL.Algorithm.Classification.Assemble import Assemble\n","from LAMDA_SSL.Algorithm.Classification.SemiBoost import SemiBoost"]},{"cell_type":"markdown","metadata":{"id":"jUUg3Iv6xZZ_"},"source":["## Co-Training (with Group k-fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7d45y5ZF_Ky"},"outputs":[],"source":["def coTraining(estimatorType, feature, label, folds, groups, labelledCount, fileName, saveLoc):\n","  # Lists to store results\n","  foldNumber = []\n","  trainAccuracy = []\n","  trainPrecision = []\n","  testAccuracy = []\n","  testPrecision = []\n","  confusionMatrixList = []\n","\n","  group_kfold = GroupKFold(n_splits = folds)\n","  for train_index, test_index in group_kfold.split(feature, label, groups):\n","    # Getting Train and Test Sets\n","    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n","    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n","\n","    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n","    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n","    random.shuffle(labeled_mask)\n","\n","    # Train Set Labelled Data\n","    labeledFeatures = trainFeatures[labeled_mask]\n","    labeledLabels = trainLabels[labeled_mask]\n","\n","    # Train Set Unlabelled Data\n","    unlabeledFeatures = trainFeatures[~labeled_mask]\n","    unlabeledLabels = trainLabels[~labeled_mask]\n","\n","    # For Evaluation\n","    evaluation={'Accuracy':Accuracy(), 'Precision':Precision(average='macro'), 'ConfusionMatrix':Confusion_Matrix()}\n","\n","    # Choosing base estimators\n","    if estimatorType == \"BLR\":\n","      estimator1 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","      estimator2 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","    elif estimatorType == \"RF\":\n","      estimator1 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","      estimator2 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","    elif estimatorType == \"NN\":\n","      estimator1 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","      estimator2 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","    else: raise Exception(\"Invalid\")\n","\n","    # Creating and fitting Model\n","    model = Co_Training(base_estimator = estimator1, base_estimator_2 = estimator2, evaluation=evaluation)\n","    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n","\n","    # Getting Performance Results\n","    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n","    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n","\n","    # Append results\n","    foldNumber.append(len(foldNumber)+1)\n","    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n","    trainPrecision.append(performanceTrain[\"Precision\"])\n","    testAccuracy.append(performanceTest[\"Accuracy\"])\n","    testPrecision.append(performanceTest[\"Precision\"])\n","    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n","\n","  # Save per fold results\n","  csvFile = pd.DataFrame({\"foldNumber\": foldNumber, \"trainAccuracy\": trainAccuracy, \"trainPrecision\": trainPrecision, \"testAccuracy\": testAccuracy, \"testPrecision\": testPrecision, \"confusionMatrix\": confusionMatrixList})\n","  csvFile.to_csv(saveLoc + \"Co-Training/Per Fold Results/\" + fileName + \".csv\", index=False)\n","\n","  # Save Confusion Matrix\n","  with open(saveLoc + \"Co-Training/ConfusionMatrices.csv\", \"a\") as file:\n","    file.write(fileName + \",\" + str(\"\".join(f\"{row}\" for row in np.mean(confusionMatrixList, axis=0)) + \"\\n\"))\n","    file.close"]},{"cell_type":"markdown","metadata":{"id":"5Hmchjlvx9Ah"},"source":["## Tri-Training (with Group k-fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OxkK5W5qU--C"},"outputs":[],"source":["def triTraining(estimatorType, feature, label, folds, groups, labelledCount, fileName, saveLoc):\n","  # Lists to store results\n","  foldNumber = []\n","  trainAccuracy = []\n","  trainPrecision = []\n","  testAccuracy = []\n","  testPrecision = []\n","  confusionMatrixList = []\n","\n","  group_kfold = GroupKFold(n_splits=folds)\n","  for train_index, test_index in group_kfold.split(feature, label, groups):\n","    # Getting Train and Test Sets\n","    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n","    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n","\n","    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n","    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n","    random.shuffle(labeled_mask)\n","\n","    # Train Set Labelled Data\n","    labeledFeatures = trainFeatures[labeled_mask]\n","    labeledLabels = trainLabels[labeled_mask]\n","\n","    # Train Set Unlabelled Data\n","    unlabeledFeatures = trainFeatures[~labeled_mask]\n","    unlabeledLabels = trainLabels[~labeled_mask]\n","\n","    # For Evaluation\n","    evaluation={\n","      'Accuracy':Accuracy(),\n","      'Precision':Precision(average='macro'),\n","      'ConfusionMatrix':Confusion_Matrix()\n","    }\n","\n","    # Choosing base estimators\n","    if estimatorType == \"BLR\":\n","      estimator1 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","      estimator2 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","      estimator3 = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","    elif estimatorType == \"RF\":\n","      estimator1 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","      estimator2 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","      estimator3 = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","    elif estimatorType == \"NN\":\n","      estimator1 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","      estimator2 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","      estimator3 = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","    else: raise Exception(\"Invalid\")\n","\n","    # Creating and fitting model\n","    model = Tri_Training(base_estimator = estimator1, base_estimator_2 = estimator2, base_estimator_3 = estimator3, evaluation = evaluation)\n","    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n","\n","    # Getting Performance Results\n","    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n","    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n","\n","    # Append results\n","    foldNumber.append(len(foldNumber)+1)\n","    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n","    trainPrecision.append(performanceTrain[\"Precision\"])\n","    testAccuracy.append(performanceTest[\"Accuracy\"])\n","    testPrecision.append(performanceTest[\"Precision\"])\n","    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n","\n","  # Save per fold results\n","  csvFile = pd.DataFrame({\"foldNumber\": foldNumber, \"trainAccuracy\": trainAccuracy, \"trainPrecision\": trainPrecision, \"testAccuracy\": testAccuracy, \"testPrecision\": testPrecision, \"confusionMatrix\": confusionMatrixList})\n","  csvFile.to_csv(saveLoc + \"Tri-Training/Per Fold Results/\" + fileName + \".csv\", index=False)\n","\n","  # Save Confusion Matrix\n","  with open(saveLoc + \"Tri-Training/ConfusionMatrices.csv\", \"a\") as file:\n","    file.write(fileName + \",\" + str(\"\".join(f\"{row}\" for row in np.mean(confusionMatrixList, axis=0)) + \"\\n\"))\n","    file.close"]},{"cell_type":"markdown","metadata":{"id":"arZ66yECKqa9"},"source":["## SSGMM (with Group k-fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bqfhhbQgTPPo"},"outputs":[],"source":["def SSGMMModel(feature, label, folds, groups, labelledCount, fileName, saveLoc):\n","  # Lists to store results\n","  foldNumber = []\n","  trainAccuracy = []\n","  trainPrecision = []\n","  testAccuracy = []\n","  testPrecision = []\n","  confusionMatrixList = []\n","\n","  group_kfold = GroupKFold(n_splits = folds)\n","  for train_index, test_index in group_kfold.split(feature, label, groups):\n","    start = time.time()\n","\n","    # Getting Train and Test Sets\n","    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n","    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n","\n","    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n","    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n","    random.shuffle(labeled_mask)\n","\n","    # Train Set Labelled Data\n","    labeledFeatures = trainFeatures[labeled_mask]\n","    labeledLabels = trainLabels[labeled_mask]\n","\n","    # Train Set Unlabelled Data\n","    unlabeledFeatures = trainFeatures[~labeled_mask]\n","\n","    # For Evaluation\n","    evaluation={\n","      'Accuracy':Accuracy(),\n","      'Precision':Precision(average='macro'),\n","      'ConfusionMatrix':Confusion_Matrix()\n","    }\n","\n","    # Creating and fitting model\n","    model = SSGMM(num_classes=2, tolerance=0.000001, max_iterations = 5, evaluation = evaluation)\n","    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n","\n","    # Getting Performance Results\n","    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n","    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n","\n","    # Append results\n","    foldNumber.append(len(foldNumber)+1)\n","    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n","    trainPrecision.append(performanceTrain[\"Precision\"])\n","    testAccuracy.append(performanceTest[\"Accuracy\"])\n","    testPrecision.append(performanceTest[\"Precision\"])\n","    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n","\n","  # Save per fold results\n","  csvFile = pd.DataFrame({\"foldNumber\": foldNumber, \"trainAccuracy\": trainAccuracy, \"trainPrecision\": trainPrecision, \"testAccuracy\": testAccuracy, \"testPrecision\": testPrecision, \"confusionMatrix\": confusionMatrixList})\n","  csvFile.to_csv(saveLoc + \"SSGMM/Per Fold Results/\" + fileName + \".csv\", index=False)\n","\n","  # Save Confusion Matrix\n","  with open(saveLoc + \"SSGMM/ConfusionMatrices.csv\", \"a\") as file:\n","    file.write(fileName + \",\" + str(\"\".join(f\"{row}\" for row in np.mean(confusionMatrixList, axis=0)) + \"\\n\"))\n","    file.close"]},{"cell_type":"markdown","metadata":{"id":"5EXgWsWQKyRy"},"source":["## Assemble (with Group k-fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6uz8afvQKXMP"},"outputs":[],"source":["def assemble(estimatorType, feature, label, folds, groups, labelledCount, fileName, saveLoc):\n","  # Lists to store results\n","  foldNumber = []\n","  trainAccuracy = []\n","  trainPrecision = []\n","  testAccuracy = []\n","  testPrecision = []\n","  confusionMatrixList = []\n","\n","  group_kfold = GroupKFold(n_splits=folds)\n","  for train_index, test_index in group_kfold.split(feature, label, groups):\n","    # Getting Train and Test Sets\n","    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n","    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n","\n","    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n","    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n","    random.shuffle(labeled_mask)\n","\n","    # Train Set Labelled Data\n","    labeledFeatures = trainFeatures[labeled_mask]\n","    labeledLabels = trainLabels[labeled_mask]\n","\n","    # Train Set Unlabelled Data\n","    unlabeledFeatures = trainFeatures[~labeled_mask]\n","\n","    # For Evaluation\n","    evaluation={\n","      'Accuracy':Accuracy(),\n","      'Precision':Precision(average='macro'),\n","      'ConfusionMatrix':Confusion_Matrix()\n","    }\n","\n","    # Choosing base estimators\n","    if estimatorType == \"BLR\":\n","      estimator = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","    elif estimatorType == \"RF\":\n","      estimator = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","    elif estimatorType == \"NN\":\n","      estimator = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","    else: raise Exception(\"Invalid\")\n","\n","    # Creating Model\n","    model = Assemble(base_estimator = estimator, evaluation = evaluation)\n","\n","    # Fitting Model\n","    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n","\n","    # Getting Performance Results\n","    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n","    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n","\n","    # Append results\n","    foldNumber.append(len(foldNumber)+1)\n","    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n","    trainPrecision.append(performanceTrain[\"Precision\"])\n","    testAccuracy.append(performanceTest[\"Accuracy\"])\n","    testPrecision.append(performanceTest[\"Precision\"])\n","    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n","\n","  # Save per fold results\n","  csvFile = pd.DataFrame({\"foldNumber\": foldNumber, \"trainAccuracy\": trainAccuracy, \"trainPrecision\": trainPrecision, \"testAccuracy\": testAccuracy, \"testPrecision\": testPrecision, \"confusionMatrix\": confusionMatrixList})\n","  csvFile.to_csv(saveLoc + \"Assemble/Per Fold Results/\" + fileName + \".csv\", index=False)\n","\n","  # Save Confusion Matrix\n","  with open(saveLoc + \"Assemble/ConfusionMatrices.csv\", \"a\") as file:\n","    file.write(fileName + \",\" + str(\"\".join(f\"{row}\" for row in np.mean(confusionMatrixList, axis=0)) + \"\\n\"))\n","    file.close"]},{"cell_type":"markdown","metadata":{"id":"Xr9Kr0ZLyMQG"},"source":["## SemiBoost (with Group k-fold)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0Kn5nURrIKb"},"outputs":[],"source":["def semiBoost(estimatorType, feature, label, folds, groups, labelledCount, fileName, saveLoc):\n","  # Lists to store results\n","  foldNumber = []\n","  trainAccuracy = []\n","  trainPrecision = []\n","  testAccuracy = []\n","  testPrecision = []\n","  confusionMatrixList = []\n","\n","  group_kfold = GroupKFold(n_splits=folds)\n","  for train_index, test_index in group_kfold.split(feature, label, groups):\n","    # Getting Train and Test Sets\n","    trainFeatures, testFeatures = feature.iloc[train_index].values, feature.iloc[test_index].values\n","    trainLabels, testLabels = label.iloc[train_index].values, label.iloc[test_index].values\n","\n","    numOfLabeledParticipants = int(len(trainLabels) * (labelledCount/16))\n","    labeled_mask = np.array([True] * numOfLabeledParticipants + [False] * (len(trainLabels) - numOfLabeledParticipants))\n","    random.shuffle(labeled_mask)\n","\n","    # Train Set Labelled Data\n","    labeledFeatures = trainFeatures[labeled_mask]\n","    labeledLabels = trainLabels[labeled_mask]\n","\n","    # Train Set Unlabelled Data\n","    unlabeledFeatures = trainFeatures[~labeled_mask]\n","    unlabeledLabels = trainLabels[~labeled_mask]\n","\n","    # For Evaluation\n","    evaluation={\n","      'Accuracy':Accuracy(),\n","      'Precision':Precision(average='macro'),\n","      'ConfusionMatrix':Confusion_Matrix()\n","    }\n","\n","    # Choosing base estimators\n","    if estimatorType == \"BLR\":\n","      estimator = LogisticRegression(solver = \"lbfgs\", max_iter = 2000)\n","    elif estimatorType == \"RF\":\n","      estimator = RandomForestClassifier(n_estimators = 50, random_state = 42)\n","    elif estimatorType == \"NN\":\n","      estimator = MLPClassifier(hidden_layer_sizes = (32,), max_iter = 10000, random_state = 42)\n","    else: raise Exception(\"Invalid\")\n","\n","    # Creating and fitting model\n","    model=SemiBoost(base_estimator=estimator, evaluation=evaluation)\n","    model.fit(X = labeledFeatures, y = labeledLabels, unlabeled_X = unlabeledFeatures)\n","\n","    # Getting Performance Results\n","    performanceTrain = model.evaluate(X = trainFeatures,y = trainLabels)\n","    performanceTest = model.evaluate(X = testFeatures,y = testLabels)\n","\n","    # Append results\n","    foldNumber.append(len(foldNumber)+1)\n","    trainAccuracy.append(performanceTrain[\"Accuracy\"])\n","    trainPrecision.append(performanceTrain[\"Precision\"])\n","    testAccuracy.append(performanceTest[\"Accuracy\"])\n","    testPrecision.append(performanceTest[\"Precision\"])\n","    confusionMatrixList.append(performanceTest[\"ConfusionMatrix\"])\n","\n","  # Save per fold results\n","  csvFile = pd.DataFrame({\"foldNumber\": foldNumber, \"trainAccuracy\": trainAccuracy, \"trainPrecision\": trainPrecision, \"testAccuracy\": testAccuracy, \"testPrecision\": testPrecision, \"confusionMatrix\": confusionMatrixList})\n","  csvFile.to_csv(saveLoc + \"SemiBoost/Per Fold Results/\" + fileName + \".csv\", index=False)\n","\n","  # Save Confusion Matrix\n","  with open(saveLoc + \"SemiBoost/ConfusionMatrices.csv\", \"a\") as file:\n","    file.write(fileName + \",\" + str(\"\".join(f\"{row}\" for row in np.mean(confusionMatrixList, axis=0)) + \"\\n\"))\n","    file.close"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNvGDS/0Z33YKlJUlXGMBjv","collapsed_sections":["HDKev4lhb-9T","jUUg3Iv6xZZ_","5Hmchjlvx9Ah","arZ66yECKqa9","5EXgWsWQKyRy","Xr9Kr0ZLyMQG"],"provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
